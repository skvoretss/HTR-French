{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e3f56a-c474-4f62-80a9-5fb45ee21cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torch.optim as optim\n",
    "import evaluate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc46be3a-5b15-4f07-bfe1-590f5f9d77c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8673e3fb3534cf3a9d57d71c0ce825c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef69ec2-d056-4dcd-9108-d0ee502a402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3eaa95e-de5f-4834-90dc-4bb45315f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "   np.random.seed(seed_value)\n",
    "   torch.manual_seed(seed_value)\n",
    "   torch.cuda.manual_seed_all(seed_value)\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "   torch.backends.cudnn.benchmark = False\n",
    " \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e58e380-34ac-4e90-a5a1-e08725c25730",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb30780-b229-4755-b02b-d28fb0a86ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url, save_path):\n",
    "    print(f\"Downloading and extracting assets....\", end=\"\")\n",
    "    urlretrieve(url, save_path)\n",
    "\n",
    "    try:\n",
    "        with ZipFile(save_path) as z:\n",
    "            z.extractall(os.path.split(save_path)[0])\n",
    "        print(\"Done\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nInvalid file.\", e)\n",
    " \n",
    "URL = r\"https://storage.teklia.com/public/rimes2011/RIMES-2011-Lines.zip\"\n",
    "asset_zip_path = os.path.join(os.getcwd(), \"Datasets/RIMES-2011-Lines.zip\")\n",
    "\n",
    "if not os.path.exists(asset_zip_path):\n",
    "    download_and_unzip(URL, asset_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871799a5-d166-4427-871c-197bac9223c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2be71f-baf5-4942-ad94-310da3efb98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-stage1')\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    'microsoft/trocr-small-stage1'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af45fa5-4956-4974-b809-b362aa1fb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3 # 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e0e0f5-cd67-43a5-934d-7eff0cdba330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIMESDataset(Dataset):\n",
    "   def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "       self.root_dir = root_dir\n",
    "       self.df = df\n",
    "       self.processor = processor\n",
    "       self.max_target_length = max_target_length\n",
    "       self.batch_size = 4\n",
    " \n",
    "       self.df['text'] = self.df['text'].fillna('')\n",
    " \n",
    " \n",
    "   def __len__(self):\n",
    "       return len(self.df)\n",
    " \n",
    " \n",
    "   def __getitem__(self, idx):\n",
    "       file_name = self.df['file_name'][idx]\n",
    "       text = self.df['text'][idx]\n",
    "\n",
    "       image = Image.open(file_name).convert('RGB')\n",
    "       pixel_values = self.processor(image, return_tensors='pt').pixel_values\n",
    "       labels = self.processor.tokenizer(\n",
    "           text,\n",
    "           padding='max_length',\n",
    "           max_length=self.max_target_length\n",
    "       ).input_ids\n",
    "\n",
    "       labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "       encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "       return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982c4769-2196-4851-bbf1-95d07f29a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(transcription_path):\n",
    "    with open(transcription_path) as f_transcription:\n",
    "        transcription = f_transcription.readline().strip()\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ecee91-3cfa-4df7-a41b-3e51d2a20b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_RIMES(dataset_path, file):\n",
    "    set_path = os.path.join(dataset_path, 'Sets')\n",
    "    images_path = os.path.join(dataset_path, 'Images')\n",
    "    text_path = os.path.join(dataset_path, 'Transcriptions')\n",
    "    dataset ={'file_name': [], 'text': []} \n",
    "\n",
    "    i = 0\n",
    "    with open(os.path.join(set_path, file)) as f:\n",
    "        for val in f:\n",
    "            dataset['file_name'].append(os.path.join(images_path, val.strip() + '.jpg'))\n",
    "            text = get_text(os.path.join(text_path, val.strip() + '.txt'))\n",
    "            dataset['text'].append(text) \n",
    "            \n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301877e1-505b-45cd-93cb-fc05e712962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=os.path.join('Datasets', 'RIMES-2011-Lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c04ea2-009b-4ba5-b07a-9466d55e03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_RIMES(dataset_path, 'TrainLines.txt')\n",
    "test_df = prepare_RIMES(dataset_path, 'TestLines.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9560b731-8181-4af8-a621-ef895728b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RIMESDataset(root_dir=dataset_path,\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "test_dataset = RIMESDataset(root_dir=dataset_path,\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f02e16-31d5-4de1-82d9-862ca97527d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4cf45f-e2f6-4436-95c7-1ce098f16af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_metric = evaluate.load('cer')\n",
    "def compute_cer(pred_ids, label_ids):\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef600e45-9d4d-4d76-b088-b5c561ba1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load('wer')\n",
    "def compute_wer(pred_ids, label_ids):\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf7b267-1fc0-4fd1-a5f7-334f7391ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_steps = 4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24106712-0925-48c5-9f72-4ae87045d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "cer_vals = []\n",
    "wer_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f48bbe2-f943-40f0-821a-09fca82f2fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866b6fa687e4c7a861f9008c281aa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0010 | Batch 0000/2547 | Loss: 2.5380\n",
      "Epoch: 0001/0010 | Batch 0300/2547 | Loss: 0.4976\n",
      "Epoch: 0001/0010 | Batch 0600/2547 | Loss: 0.2476\n",
      "Epoch: 0001/0010 | Batch 0900/2547 | Loss: 0.3102\n",
      "Epoch: 0001/0010 | Batch 1200/2547 | Loss: 0.2772\n",
      "Epoch: 0001/0010 | Batch 1500/2547 | Loss: 0.3139\n",
      "Epoch: 0001/0010 | Batch 1800/2547 | Loss: 0.2017\n",
      "Epoch: 0001/0010 | Batch 2100/2547 | Loss: 0.1906\n",
      "Epoch: 0001/0010 | Batch 2400/2547 | Loss: 0.2093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8b1fadf7154051b5d6447ffee0b3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1338: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.16317000041528312\n",
      "Validation WER: 0.3498530799381593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a250fd45f4962bf0d7aea3f335e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002/0010 | Batch 0000/2547 | Loss: 0.1621\n",
      "Epoch: 0002/0010 | Batch 0300/2547 | Loss: 0.6846\n",
      "Epoch: 0002/0010 | Batch 0600/2547 | Loss: 0.2419\n",
      "Epoch: 0002/0010 | Batch 0900/2547 | Loss: 0.1515\n",
      "Epoch: 0002/0010 | Batch 1200/2547 | Loss: 0.1236\n",
      "Epoch: 0002/0010 | Batch 1500/2547 | Loss: 0.1711\n",
      "Epoch: 0002/0010 | Batch 1800/2547 | Loss: 0.1747\n",
      "Epoch: 0002/0010 | Batch 2100/2547 | Loss: 0.2262\n",
      "Epoch: 0002/0010 | Batch 2400/2547 | Loss: 0.0903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d545bec1ff445d800eb9cbdc5c998a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.195517271957147\n",
      "Validation WER: 0.3644511242234529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9de453f82b43ac80415cda1765e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003/0010 | Batch 0000/2547 | Loss: 0.0991\n",
      "Epoch: 0003/0010 | Batch 0300/2547 | Loss: 0.0647\n",
      "Epoch: 0003/0010 | Batch 0600/2547 | Loss: 0.1203\n",
      "Epoch: 0003/0010 | Batch 0900/2547 | Loss: 0.0525\n",
      "Epoch: 0003/0010 | Batch 1200/2547 | Loss: 0.1275\n",
      "Epoch: 0003/0010 | Batch 1500/2547 | Loss: 0.0980\n",
      "Epoch: 0003/0010 | Batch 1800/2547 | Loss: 0.1632\n",
      "Epoch: 0003/0010 | Batch 2100/2547 | Loss: 0.1936\n",
      "Epoch: 0003/0010 | Batch 2400/2547 | Loss: 0.0746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c4415933a641a2ac0f99e5fb49bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.12319982827631544\n",
      "Validation WER: 0.2550179774994266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5701dc7c72c9407f85321ec0578b5f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0004/0010 | Batch 0000/2547 | Loss: 0.2410\n",
      "Epoch: 0004/0010 | Batch 0300/2547 | Loss: 0.1787\n",
      "Epoch: 0004/0010 | Batch 0600/2547 | Loss: 0.1110\n",
      "Epoch: 0004/0010 | Batch 0900/2547 | Loss: 0.2283\n",
      "Epoch: 0004/0010 | Batch 1200/2547 | Loss: 0.0670\n",
      "Epoch: 0004/0010 | Batch 1500/2547 | Loss: 0.1231\n",
      "Epoch: 0004/0010 | Batch 1800/2547 | Loss: 0.0593\n",
      "Epoch: 0004/0010 | Batch 2100/2547 | Loss: 0.1999\n",
      "Epoch: 0004/0010 | Batch 2400/2547 | Loss: 0.1107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134b3b56f2064aee94b86edc2046f089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.14404253751637805\n",
      "Validation WER: 0.27346333680977225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5483751f65784ece918899288d155a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005/0010 | Batch 0000/2547 | Loss: 0.1128\n",
      "Epoch: 0005/0010 | Batch 0300/2547 | Loss: 0.0881\n",
      "Epoch: 0005/0010 | Batch 0600/2547 | Loss: 0.1085\n",
      "Epoch: 0005/0010 | Batch 0900/2547 | Loss: 0.1401\n",
      "Epoch: 0005/0010 | Batch 1200/2547 | Loss: 0.1049\n",
      "Epoch: 0005/0010 | Batch 1500/2547 | Loss: 0.0399\n",
      "Epoch: 0005/0010 | Batch 1800/2547 | Loss: 0.1907\n",
      "Epoch: 0005/0010 | Batch 2100/2547 | Loss: 0.0548\n",
      "Epoch: 0005/0010 | Batch 2400/2547 | Loss: 0.0564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660717620c754f52b2c35bd7a2a4e11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.6725324172267129\n",
      "Validation WER: 0.8832013633924654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b566bba105a145b8a07ee1ec74277cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006/0010 | Batch 0000/2547 | Loss: 0.9332\n",
      "Epoch: 0006/0010 | Batch 0300/2547 | Loss: 0.1173\n",
      "Epoch: 0006/0010 | Batch 0600/2547 | Loss: 0.0791\n",
      "Epoch: 0006/0010 | Batch 0900/2547 | Loss: 0.1022\n",
      "Epoch: 0006/0010 | Batch 1200/2547 | Loss: 0.0475\n",
      "Epoch: 0006/0010 | Batch 1500/2547 | Loss: 0.0740\n",
      "Epoch: 0006/0010 | Batch 1800/2547 | Loss: 0.0641\n",
      "Epoch: 0006/0010 | Batch 2100/2547 | Loss: 0.0603\n",
      "Epoch: 0006/0010 | Batch 2400/2547 | Loss: 0.1208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8859f165794079a64741b8ff3d90c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.07287212245441983\n",
      "Validation WER: 0.18346381166577205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383771ae0a9b471899ba817b6e4d8df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007/0010 | Batch 0000/2547 | Loss: 0.0278\n",
      "Epoch: 0007/0010 | Batch 0300/2547 | Loss: 0.0353\n",
      "Epoch: 0007/0010 | Batch 0600/2547 | Loss: 0.0176\n",
      "Epoch: 0007/0010 | Batch 0900/2547 | Loss: 0.0644\n",
      "Epoch: 0007/0010 | Batch 1200/2547 | Loss: 0.0124\n",
      "Epoch: 0007/0010 | Batch 1500/2547 | Loss: 0.0336\n",
      "Epoch: 0007/0010 | Batch 1800/2547 | Loss: 0.0128\n",
      "Epoch: 0007/0010 | Batch 2100/2547 | Loss: 0.0248\n",
      "Epoch: 0007/0010 | Batch 2400/2547 | Loss: 0.0272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0175d49c0d24135bdea35fb60c94182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.07107539426098575\n",
      "Validation WER: 0.18086406036459762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be916fb58d64dec80022d3ed97a7f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0008/0010 | Batch 0000/2547 | Loss: 0.0109\n",
      "Epoch: 0008/0010 | Batch 0300/2547 | Loss: 0.0139\n",
      "Epoch: 0008/0010 | Batch 0600/2547 | Loss: 0.0185\n",
      "Epoch: 0008/0010 | Batch 0900/2547 | Loss: 0.1641\n",
      "Epoch: 0008/0010 | Batch 1200/2547 | Loss: 0.1202\n",
      "Epoch: 0008/0010 | Batch 1500/2547 | Loss: 0.0746\n",
      "Epoch: 0008/0010 | Batch 1800/2547 | Loss: 0.0087\n",
      "Epoch: 0008/0010 | Batch 2100/2547 | Loss: 0.0666\n",
      "Epoch: 0008/0010 | Batch 2400/2547 | Loss: 0.0568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eedf44187c240d6aa7ef4224667c899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.06591462965335806\n",
      "Validation WER: 0.1695512273816187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4b4b6542ad4cd9a05919a470f04a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009/0010 | Batch 0000/2547 | Loss: 0.0285\n",
      "Epoch: 0009/0010 | Batch 0300/2547 | Loss: 0.0172\n",
      "Epoch: 0009/0010 | Batch 0600/2547 | Loss: 0.0092\n",
      "Epoch: 0009/0010 | Batch 0900/2547 | Loss: 0.0591\n",
      "Epoch: 0009/0010 | Batch 1200/2547 | Loss: 0.0186\n",
      "Epoch: 0009/0010 | Batch 1500/2547 | Loss: 0.0397\n",
      "Epoch: 0009/0010 | Batch 1800/2547 | Loss: 0.0654\n",
      "Epoch: 0009/0010 | Batch 2100/2547 | Loss: 0.0073\n",
      "Epoch: 0009/0010 | Batch 2400/2547 | Loss: 0.0291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0795e743f5d44cb5befac520a0872e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.0691755150620948\n",
      "Validation WER: 0.17318745022847917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d2b58e91b04ec3a9cfd13dda08cb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010/0010 | Batch 0000/2547 | Loss: 0.0051\n",
      "Epoch: 0010/0010 | Batch 0300/2547 | Loss: 0.0162\n",
      "Epoch: 0010/0010 | Batch 0600/2547 | Loss: 0.0472\n",
      "Epoch: 0010/0010 | Batch 0900/2547 | Loss: 0.0255\n",
      "Epoch: 0010/0010 | Batch 1200/2547 | Loss: 0.0771\n",
      "Epoch: 0010/0010 | Batch 1500/2547 | Loss: 0.1258\n",
      "Epoch: 0010/0010 | Batch 1800/2547 | Loss: 0.0287\n",
      "Epoch: 0010/0010 | Batch 2100/2547 | Loss: 0.1226\n",
      "Epoch: 0010/0010 | Batch 2400/2547 | Loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3867ab6bfbcf442fbc1574b1ee6266cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation CER: 0.0691366601482624\n",
      "Validation WER: 0.17338457942174382\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "   # train\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        for k,v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "            ### FORWARD AND BACK PROP   \n",
    "        outputs = model(**batch) \n",
    "\n",
    "        outputs[\"loss\"] = outputs[\"loss\"] / accumulation_steps\n",
    "        outputs[\"loss\"].backward()\n",
    "\n",
    "            ### UPDATE MODEL PARAMETERS\n",
    "        if not batch_idx % accumulation_steps:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ### LOGGING\n",
    "        if not batch_idx % 300:\n",
    "            print(f\"Epoch: {epoch+1:04d}/{num_epochs:04d} \"\n",
    "                    f\"| Batch {batch_idx:04d}/{len(train_dataloader):04d} \"\n",
    "                    f\"| Loss: {outputs['loss']:.4f}\")\n",
    "\n",
    "        batch_idx += 1\n",
    "        \n",
    "    model.eval()\n",
    "    valid_cer = 0.0\n",
    "    valid_wer = 0.0 \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "       # run batch generation\n",
    "            outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "       # compute metrics\n",
    "            cer = compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "            wer = compute_wer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "         \n",
    "            valid_cer += cer\n",
    "            valid_wer += wer\n",
    "    \n",
    "    cer_vals.append(valid_cer / len(eval_dataloader))\n",
    "    wer_vals.append(valid_wer / len(eval_dataloader)) \n",
    "    print(\"Validation CER:\", valid_cer / len(eval_dataloader))\n",
    "    print(\"Validation WER:\", valid_wer / len(eval_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2cfa4-2e2b-4d89-a20f-09b1f5c5225b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bea496bcd284c4cb382021bc4d158cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "cer_vals = []\n",
    "wer_vals = []\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "   # train\n",
    "   model.train()\n",
    "   train_loss = 0.0\n",
    "   for batch in tqdm(train_dataloader):\n",
    "      # get the inputs\n",
    "      #print (batch)\n",
    "      for k,v in batch.items():\n",
    "        batch[k] = v.to(device)\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_loss += loss.item()\n",
    "\n",
    "   print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n",
    "    \n",
    "   # evaluate\n",
    "   model.eval()\n",
    "   valid_cer = 0.0\n",
    "   valid_wer = 0.0 \n",
    "   with torch.no_grad():\n",
    "     for batch in tqdm(eval_dataloader):\n",
    "       # run batch generation\n",
    "       outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "       # compute metrics\n",
    "       cer = compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "       wer = compute_wer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "         \n",
    "       valid_cer += cer\n",
    "       valid_wer += wer\n",
    "    \n",
    "   cer_vals.append(valid_cer / len(eval_dataloader))\n",
    "   wer_vals.append(valid_wer / len(eval_dataloader)) \n",
    "   print(\"Validation CER:\", valid_cer / len(eval_dataloader))\n",
    "   print(\"Validation WER:\", valid_wer / len(eval_dataloader)) \n",
    "\n",
    "#model.save_pretrained(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "830d132d-60dd-48be-a629-61f1f63054aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 64, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595a84ee622c4ad48e335d8854859edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/skvoretss/trocr-base-stage1-42-batch-16/commit/e5d756444294f15933747fcfc76150c386118cfd', commit_message='Upload model', commit_description='', oid='e5d756444294f15933747fcfc76150c386118cfd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/skvoretss/trocr-base-stage1-42-batch-16', endpoint='https://huggingface.co', repo_type='model', repo_id='skvoretss/trocr-base-stage1-42-batch-16'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"trocr-base-stage1-42-batch-16\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7d37744-80d5-45c8-ae7b-1cfd4390857f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cpu' has no attribute 'memory_allocated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcpu\u001b[38;5;241m.\u001b[39mmemory_allocated(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cpu' has no attribute 'memory_allocated'"
     ]
    }
   ],
   "source": [
    "torch.cpu.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a4032c1-0f18-4ccb-b0b2-b556f1eb585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789782528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b0633b1-0327-4745-baa5-23e85fd21113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7608467456"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_reserved(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "153539cc-2330-49e3-a021-a91d87ae019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3235905536"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a80b8c-2f20-42b4-ae39-32ad0036a46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
